{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cde838ec-044b-4bb7-8a9b-e9661bc293fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\admin\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\admin\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d05363d8-961e-4191-bc3a-c8d9f5dd832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\" Helo welcome to anemoi nlp tutorial. plase do watch the entire video!,to becom expert in nlp.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "854181ff-4689-43c6-9e1c-90d8d0d121fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf216db5-9990-4cf5-9370-c8b553e41479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt_tab: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc40e6af-cfc7-4ff8-87c3-75bb0c49ecd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Helo welcome to anemoi nlp tutorial. plase do watch the entire video,to becom expert in nlp\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62162484-d99f-48fe-b631-3543d44bd804",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba11b609-1001-47de-87f3-03951534aebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Helo welcome to anemoi nlp tutorial.\n",
      "plase do watch the entire video!,to becom expert in nlp.\n"
     ]
    }
   ],
   "source": [
    "for sentences in documents:\n",
    "    print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097ef01f-f397-4a3c-bd79-4caa3da38b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "### conevert paregraph to words\n",
    "## sentece to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdf4c19c-4c70-40ea-a43f-80ad44d6c457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4955a56-2cb0-437a-818d-055d268649f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Helo',\n",
       " 'welcome',\n",
       " 'to',\n",
       " 'anemoi',\n",
       " 'nlp',\n",
       " 'tutorial',\n",
       " '.',\n",
       " 'plase',\n",
       " 'do',\n",
       " 'watch',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'video',\n",
       " '!',\n",
       " ',',\n",
       " 'to',\n",
       " 'becom',\n",
       " 'expert',\n",
       " 'in',\n",
       " 'nlp',\n",
       " '.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5970e2ab-9807-4e85-901f-bdc916724289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Helo', 'welcome', 'to', 'anemoi', 'nlp', 'tutorial', '.']\n",
      "['plase', 'do', 'watch', 'the', 'entire', 'video', '!', ',', 'to', 'becom', 'expert', 'in', 'nlp', '.']\n"
     ]
    }
   ],
   "source": [
    "for sentences in documents:\n",
    "    print(word_tokenize(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4aa45cb1-9902-4458-98a5-65c7a5731da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Helo', 'welcome', 'to', 'anemoi', 'nlp', 'tutorial.', 'plase', 'do', 'watch', 'the', 'entire', 'video', '!', ',', 'to', 'becom', 'expert', 'in', 'nlp', '.']\n"
     ]
    }
   ],
   "source": [
    "# from nltk.tokenize import treebankWordTokenizer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "tokens = tokenizer.tokenize(corpus)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5192f2-a55d-4cb9-8990-2623fd40c148",
   "metadata": {},
   "outputs": [],
   "source": [
    "##stemomg \n",
    "#PorterStemmer\n",
    "# stemming is means that convert cored to base word like going ,gone,to go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "78f70f86-1abb-4c2e-a232-319c7a1aeb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"drinking\",\"playing\",\"going\",\"programs\",\"history\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c69a865-ddcd-4586-9950-59dd69e2f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ec3c415-635a-456e-910b-2889ddff7a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "742ff524-0dbb-4864-9b10-8b78144939bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating-------------->eat\n",
      "eats-------------->eat\n",
      "eaten-------------->eaten\n",
      "writing-------------->write\n",
      "writes-------------->write\n",
      "programming-------------->program\n",
      "drinking-------------->drink\n",
      "playing-------------->play\n",
      "going-------------->go\n",
      "programs-------------->program\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"-------------->\"+stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fa9ef3-3c1c-4f5d-a1ed-3b31eaae377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###RegexStemmer Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4861e47d-e590-42b4-9b78-16ce2b37930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a2e7840c-efb4-4dd8-8e48-44f1171cc01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_steam=RegexpStemmer('ing$|s$|e$|able$',min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5c05b3f0-eca4-407a-8c39-56ac90e77aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_steam.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ca75da9b-6d56-4494-9136-d4a2e17d3cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_steam.stem('ingeat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237aa4a5-28f1-4093-81cc-bd39e7f9c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## snowball Stemmer Better thet all stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bb8c9810-31fd-4845-9a2a-e95ddd1eaf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7ea1df66-9d55-47e6-a867-1f42bffcd122",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_stem=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "abe5e5c8-c873-4e82-ad4b-eb1dd0885e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating----------------->eat\n",
      "eats----------------->eat\n",
      "eaten----------------->eaten\n",
      "writing----------------->write\n",
      "writes----------------->write\n",
      "programming----------------->program\n",
      "drinking----------------->drink\n",
      "playing----------------->play\n",
      "going----------------->go\n",
      "programs----------------->program\n",
      "history----------------->histori\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"----------------->\"+s_stem.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bcf336-d32c-4dd1-9b70-badc4d960b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Limitization is konwn as stem\n",
    "# text summerization,Q and A, Chat boat\n",
    "### Wordnet Lemmatize- give the root word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "056fefd8-f6a9-41e5-acf5-d67e08a6eb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7ca34264-5a66-4349-abcf-afa42ea7446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmetizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a3b5a7a4-eb4c-48c5-bf03-af4fa4416d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating----------------->eat\n",
      "eats----------------->eat\n",
      "eaten----------------->eat\n",
      "writing----------------->write\n",
      "writes----------------->write\n",
      "programming----------------->program\n",
      "drinking----------------->drink\n",
      "playing----------------->play\n",
      "going----------------->go\n",
      "programs----------------->program\n",
      "history----------------->history\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "POS-Noun-n\n",
    "verb-v,\n",
    "adjective-a\n",
    "adverb -r\n",
    "'''\n",
    "for word in words:\n",
    "    print(word+\"----------------->\"+lemmetizer.lemmatize(word,pos='v'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c6d791-563f-466a-b274-9f5f6a6f31b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### text pre processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "822fccf4-2616-4117-9d24-7ef3371e534b",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph1=\"\"\"Dream is not that which you see while sleeping, it is something that does not let you sleep. My young friends, each one of you has a unique talent and a special purpose in life. Knowledge, when combined with hard work and integrity, can transform you into a source of light for others. Failures may come, but they are only the stepping stones to success. If you have the courage to dream, the determination to pursue, and the will to serve the nation, then nothing can stop you from creating a better India.My young friends, to achieve greatness in life, you must follow five golden steps: (1) Dream big — because dreams are the seeds of reality, (2) Gain knowledge — read for at least 30 minutes every day to expand your mind, (3) Work hard — give 100% effort in every task you do, (4) Learn from failures — even if you fail 10 times, rise the 11th time with more strength, and (5) Serve the nation — dedicate at least 1 hour every week to helping your community. If you follow these steps with dedication, by the year 2047, when India celebrates 100 years of independence, you will be the proud architects of a developed nation.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a352062-dc2f-44f5-84b7-1fef24a13831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cabd2f7a-11af-4eae-a52e-e86b1dd9104c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89df0fdb-5cc3-4304-9805-238f34498e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c705095-5e97-4311-809d-9480a2e6d9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41f8757d-e829-4605-83a7-28d3982f19ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "189ed7e7-f7ee-4ac7-8882-5a2d9fb83f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\"Dream is not that which you see while sleeping, it is something that does not let you sleep. My young friends, each one of you has a unique talent and a special purpose in life. Knowledge, when combined with hard work and integrity, can transform you into a source of light for others. Failures may come, but they are only the stepping stones to success. If you have the courage to dream, the determination to pursue, and the will to serve the nation, then nothing can stop you from creating a better India.My young friends, to achieve greatness in life, you must follow five golden steps: (1) Dream big — because dreams are the seeds of reality, (2) Gain knowledge — read for at least 30 minutes every day to expand your mind, (3) Work hard — give 100% effort in every task you do, (4) Learn from failures — even if you fail 10 times, rise the 11th time with more strength, and (5) Serve the nation — dedicate at least 1 hour every week to helping your community. If you follow these steps with dedication, by the year 2047, when India celebrates 100 years of independence, you will be the proud architects of a developed nation.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b568b6fd-a14c-4468-8b73-33df5b82b160",
   "metadata": {},
   "outputs": [],
   "source": [
    "senteces=nltk.sent_tokenize(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a97eb76-351e-46f0-aecb-ca1361ce3277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dream', 'is', 'not', 'that', 'which', 'you', 'see', 'while', 'sleeping', ',', 'it', 'is', 'something', 'that', 'does', 'not', 'let', 'you', 'sleep', '.']\n",
      "['My', 'young', 'friends', ',', 'each', 'one', 'of', 'you', 'has', 'a', 'unique', 'talent', 'and', 'a', 'special', 'purpose', 'in', 'life', '.']\n",
      "['Knowledge', ',', 'when', 'combined', 'with', 'hard', 'work', 'and', 'integrity', ',', 'can', 'transform', 'you', 'into', 'a', 'source', 'of', 'light', 'for', 'others', '.']\n",
      "['Failures', 'may', 'come', ',', 'but', 'they', 'are', 'only', 'the', 'stepping', 'stones', 'to', 'success', '.']\n",
      "['If', 'you', 'have', 'the', 'courage', 'to', 'dream', ',', 'the', 'determination', 'to', 'pursue', ',', 'and', 'the', 'will', 'to', 'serve', 'the', 'nation', ',', 'then', 'nothing', 'can', 'stop', 'you', 'from', 'creating', 'a', 'better', 'India.My', 'young', 'friends', ',', 'to', 'achieve', 'greatness', 'in', 'life', ',', 'you', 'must', 'follow', 'five', 'golden', 'steps', ':', '(', '1', ')', 'Dream', 'big', '—', 'because', 'dreams', 'are', 'the', 'seeds', 'of', 'reality', ',', '(', '2', ')', 'Gain', 'knowledge', '—', 'read', 'for', 'at', 'least', '30', 'minutes', 'every', 'day', 'to', 'expand', 'your', 'mind', ',', '(', '3', ')', 'Work', 'hard', '—', 'give', '100', '%', 'effort', 'in', 'every', 'task', 'you', 'do', ',', '(', '4', ')', 'Learn', 'from', 'failures', '—', 'even', 'if', 'you', 'fail', '10', 'times', ',', 'rise', 'the', '11th', 'time', 'with', 'more', 'strength', ',', 'and', '(', '5', ')', 'Serve', 'the', 'nation', '—', 'dedicate', 'at', 'least', '1', 'hour', 'every', 'week', 'to', 'helping', 'your', 'community', '.']\n",
      "['If', 'you', 'follow', 'these', 'steps', 'with', 'dedication', ',', 'by', 'the', 'year', '2047', ',', 'when', 'India', 'celebrates', '100', 'years', 'of', 'independence', ',', 'you', 'will', 'be', 'the', 'proud', 'architects', 'of', 'a', 'developed', 'nation', '.']\n"
     ]
    }
   ],
   "source": [
    "# for sentence in senteces:\n",
    "#     print(nltk.word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2245932-6bd4-418d-bd60-14fb17368de5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9103840-0de6-4e70-a370-d4afbefddff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply stop word based on steming\n",
    "for sentence in range(len(senteces)):\n",
    "    words=nltk.word_tokenize(senteces[sentence])\n",
    "    words=[stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    senteces[sentence]=' '.join(words)#converting alla word in sentences\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ddb9b453-a8fd-4db9-a291-2d5d4d6d7383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dream see sleep , someth let sleep .',\n",
       " 'my young friend , one uniqu talent special purpos life .',\n",
       " 'knowledg , combin hard work integr , transform sourc light other .',\n",
       " 'failur may come , step stone success .',\n",
       " 'if courag dream , determin pursu , serv nation , noth stop creat better india.mi young friend , achiev great life , must follow five golden step : ( 1 ) dream big — dream seed realiti , ( 2 ) gain knowledg — read least 30 minut everi day expand mind , ( 3 ) work hard — give 100 % effort everi task , ( 4 ) learn failur — even fail 10 time , rise 11th time strength , ( 5 ) serv nation — dedic least 1 hour everi week help commun .',\n",
       " 'if follow step dedic , year 2047 , india celebr 100 year independ , proud architect develop nation .']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senteces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6c8ce48-a24e-40bb-8262-477605716f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# snlw ball stammer\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "S_stemmer=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8bfec425-a775-4d42-86e1-98b1452f65a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in range(len(senteces)):\n",
    "    words=nltk.word_tokenize(senteces[sentence])\n",
    "    words=[S_stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    senteces[sentence]=' '.join(words)#converting alla word in sentences\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "31b9f8d2-7daf-468c-bb8c-7dae9132a104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dream see sleep , someth let sleep .',\n",
       " 'my young friend , one uniqu talent special purpos life .',\n",
       " 'knowledg , combin hard work integr , transform sourc light other .',\n",
       " 'failur may come , step stone success .',\n",
       " 'if courag dream , determin pursu , serv nation , noth stop creat better india.mi young friend , achiev great life , must follow five golden step : ( 1 ) dream big — dream seed realiti , ( 2 ) gain knowledg — read least 30 minut everi day expand mind , ( 3 ) work hard — give 100 % effort everi task , ( 4 ) learn failur — even fail 10 time , rise 11th time strength , ( 5 ) serv nation — dedic least 1 hour everi week help communiti .',\n",
       " 'if follow step dedic , year 2047 , india celebr 100 year independ , proud architect develop nation .']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senteces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d0cdc750-c429-4c9b-90e1-18ac6698fab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "49fc0a7b-d39b-4c17-9a1c-e353234b5305",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in range(len(senteces)):\n",
    "    words=nltk.word_tokenize(senteces[sentence])\n",
    "    words=[lemmatizer.lemmatize(word.lower(),pos='v') for word in words if word not in set(stopwords.words('english'))]\n",
    "    senteces[sentence]=' '.join(words)#converting alla word in sentences\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45ab9cb0-d20e-4896-95e5-b698dc38b295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dream see sleep , someth let sleep .',\n",
       " 'young friend , one uniqu talent special purpos life .',\n",
       " 'knowledg , combin hard work integr , transform sourc light .',\n",
       " 'failur may come , step stone success .',\n",
       " 'courag dream , determin pursu , serv nation , noth stop creat better india.mi young friend , achiev great life , must follow five golden step : ( 1 ) dream big — dream seed realiti , ( 2 ) gain knowledg — read least 30 minut everi day expand mind , ( 3 ) work hard — give 100 % effort everi task , ( 4 ) learn failur — even fail 10 time , rise 11th time strength , ( 5 ) serv nation — dedic least 1 hour everi week help communiti .',\n",
       " 'follow step dedic , year 2047 , india celebr 100 year independ , proud architect develop nation .']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senteces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04553d5-aebd-46b8-ae57-f7ba59afd83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### part of speech taging to word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "63dcef56-14cd-4da1-9788-866dcedbdb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "sentences=nltk.sent_tokenize(paragraph1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a07099f4-0968-4e26-ad29-15a48e1ad4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading averaged_perceptron_tagger_eng: <urlopen\n",
      "[nltk_data]     error [Errno 11001] getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "935c2987-7637-48a3-8279-d4ad6235d436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dream is not that which you see while sleeping, it is something that does not let you sleep.',\n",
       " 'My young friends, each one of you has a unique talent and a special purpose in life.',\n",
       " 'Knowledge, when combined with hard work and integrity, can transform you into a source of light for others.',\n",
       " 'Failures may come, but they are only the stepping stones to success.',\n",
       " 'If you have the courage to dream, the determination to pursue, and the will to serve the nation, then nothing can stop you from creating a better India.My young friends, to achieve greatness in life, you must follow five golden steps: (1) Dream big — because dreams are the seeds of reality, (2) Gain knowledge — read for at least 30 minutes every day to expand your mind, (3) Work hard — give 100% effort in every task you do, (4) Learn from failures — even if you fail 10 times, rise the 11th time with more strength, and (5) Serve the nation — dedicate at least 1 hour every week to helping your community.',\n",
       " 'If you follow these steps with dedication, by the year 2047, when India celebrates 100 years of independence, you will be the proud architects of a developed nation.']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1ed95e9d-319e-4323-a7c1-ffb5de2fcd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Dream', 'NNP'), ('see', 'NN'), ('sleeping', 'NN'), (',', ','), ('something', 'NN'), ('let', 'JJ'), ('sleep', 'NN'), ('.', '.')]\n",
      "[('My', 'PRP$'), ('young', 'JJ'), ('friends', 'NNS'), (',', ','), ('one', 'CD'), ('unique', 'NN'), ('talent', 'NN'), ('special', 'JJ'), ('purpose', 'JJ'), ('life', 'NN'), ('.', '.')]\n",
      "[('Knowledge', 'NNP'), (',', ','), ('combined', 'VBN'), ('hard', 'JJ'), ('work', 'NN'), ('integrity', 'NN'), (',', ','), ('transform', 'VB'), ('source', 'NN'), ('light', 'JJ'), ('others', 'NNS'), ('.', '.')]\n",
      "[('Failures', 'NNS'), ('may', 'MD'), ('come', 'VB'), (',', ','), ('stepping', 'VBG'), ('stones', 'NNS'), ('success', 'NN'), ('.', '.')]\n",
      "[('If', 'IN'), ('courage', 'JJ'), ('dream', 'NN'), (',', ','), ('determination', 'NN'), ('pursue', 'NN'), (',', ','), ('serve', 'VB'), ('nation', 'NN'), (',', ','), ('nothing', 'NN'), ('stop', 'NN'), ('creating', 'VBG'), ('better', 'JJR'), ('India.My', 'NNP'), ('young', 'JJ'), ('friends', 'NNS'), (',', ','), ('achieve', 'VBP'), ('greatness', 'JJ'), ('life', 'NN'), (',', ','), ('must', 'MD'), ('follow', 'VB'), ('five', 'CD'), ('golden', 'JJ'), ('steps', 'NNS'), (':', ':'), ('(', '('), ('1', 'CD'), (')', ')'), ('Dream', 'NN'), ('big', 'JJ'), ('—', 'NN'), ('dreams', 'NNS'), ('seeds', 'NNS'), ('reality', 'NN'), (',', ','), ('(', '('), ('2', 'CD'), (')', ')'), ('Gain', 'NNP'), ('knowledge', 'NN'), ('—', 'NNP'), ('read', 'VBD'), ('least', 'JJS'), ('30', 'CD'), ('minutes', 'NNS'), ('every', 'DT'), ('day', 'NN'), ('expand', 'VB'), ('mind', 'NN'), (',', ','), ('(', '('), ('3', 'CD'), (')', ')'), ('Work', 'NNP'), ('hard', 'JJ'), ('—', 'NNP'), ('give', 'VB'), ('100', 'CD'), ('%', 'NN'), ('effort', 'NN'), ('every', 'DT'), ('task', 'NN'), (',', ','), ('(', '('), ('4', 'CD'), (')', ')'), ('Learn', 'NNP'), ('failures', 'VBZ'), ('—', 'NNP'), ('even', 'RB'), ('fail', 'VBD'), ('10', 'CD'), ('times', 'NNS'), (',', ','), ('rise', 'VB'), ('11th', 'CD'), ('time', 'NN'), ('strength', 'NN'), (',', ','), ('(', '('), ('5', 'CD'), (')', ')'), ('Serve', 'NNP'), ('nation', 'NN'), ('—', 'NNP'), ('dedicate', 'NN'), ('least', 'VBD'), ('1', 'CD'), ('hour', 'NN'), ('every', 'DT'), ('week', 'NN'), ('helping', 'VBG'), ('community', 'NN'), ('.', '.')]\n",
      "[('If', 'IN'), ('follow', 'JJ'), ('steps', 'NNS'), ('dedication', 'NN'), (',', ','), ('year', 'NN'), ('2047', 'CD'), (',', ','), ('India', 'NNP'), ('celebrates', 'VBZ'), ('100', 'CD'), ('years', 'NNS'), ('independence', 'NN'), (',', ','), ('proud', 'JJ'), ('architects', 'NNS'), ('developed', 'VBN'), ('nation', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "#find out pos tag\n",
    "for i in range(len(sentences)):\n",
    "    words=nltk.word_tokenize(sentences[i])\n",
    "    words=[word for word in words if word not in set(stopwords.words('english'))]\n",
    "    nlt_pos_tag=nltk.pos_tag(words)\n",
    "    print(nlt_pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0341d594-88f0-4ad0-a289-6413854f855a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Taj', 'NN')]\n",
      "[('Mahal', 'NN')]\n",
      "[('Is', 'NN')]\n",
      "[('a', 'DT')]\n",
      "[('beautiful', 'NN')]\n",
      "[('Monument', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in \"Taj Mahal Is a beautiful Monument\".split():\n",
    "    # print(i)\n",
    "    print(nltk.pos_tag([i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "16ef8f1e-2b5d-42bb-b31b-8addc0d2c264",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('maxent_ne_chunker_tab')\n",
    "nltk.download('words')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f85f9f24-7243-46d5-b1cc-039736b4f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\"Dream is not that which you see while sleeping, it is something that does not let you sleep. My young friends, each one of you has a unique talent and a special purpose in life. Knowledge, when combined with hard work and integrity, can transform you into a source of light for others. Failures may come, but they are only the stepping stones to success. If you have the courage to dream, the determination to pursue, and the will to serve the nation, then nothing can stop you from creating a better India.My young friends, to achieve greatness in life, you must follow five golden steps: (1) Dream big — because dreams are the seeds of reality, (2) Gain knowledge — read for at least 30 minutes every day to expand your mind, (3) Work hard — give 100% effort in every task you do, (4) Learn from failures — even if you fail 10 times, rise the 11th time with more strength, and (5) Serve the nation — dedicate at least 1 hour every week to helping your community. If you follow these steps with dedication, by the year 2047, when India celebrates 100 years of independence, you will be the proud architects of a developed nation.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "038f7163-0e32-4f49-8b47-17b57d384c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neme Entity Recognition\n",
    "import nltk\n",
    "words=nltk.word_tokenize(corpus)\n",
    "tag_element=nltk.pos_tag(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08192471-936b-4c9b-9997-d2a05f4e2645",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.ne_chunk(tag_element).draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
